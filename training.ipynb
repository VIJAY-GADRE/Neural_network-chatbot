{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"training.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNXjRo+A3BFiLrSF3PzgQ62"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OVLpZQvNAvjT","executionInfo":{"status":"ok","timestamp":1615787597064,"user_tz":-330,"elapsed":1155,"user":{"displayName":"Vijay Gadre","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_amMOq8nGHFNugKpgOvJ0JOzchYXo4KFdCiNq_Q=s64","userId":"05393130732673909552"}},"outputId":"174bc59c-335a-4135-9a5c-a17cb6b5a542"},"source":["import nltk\n","nltk.download('punkt')\n","nltk.download('wordnet')"],"execution_count":26,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"nzVRZr3o9xta","executionInfo":{"status":"ok","timestamp":1615787597486,"user_tz":-330,"elapsed":1573,"user":{"displayName":"Vijay Gadre","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_amMOq8nGHFNugKpgOvJ0JOzchYXo4KFdCiNq_Q=s64","userId":"05393130732673909552"}}},"source":["import random\n","import json\n","import pickle\n","import numpy as np\n","\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Activation, Dropout\n","from tensorflow.keras.optimizers import SGD"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"JdCGQubF_Gxv","executionInfo":{"status":"ok","timestamp":1615787597487,"user_tz":-330,"elapsed":1573,"user":{"displayName":"Vijay Gadre","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_amMOq8nGHFNugKpgOvJ0JOzchYXo4KFdCiNq_Q=s64","userId":"05393130732673909552"}}},"source":["lemmatizer = WordNetLemmatizer()\n","intents = json.loads(open('intents.json').read())"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"ALExnwPPKu6n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615787597487,"user_tz":-330,"elapsed":1565,"user":{"displayName":"Vijay Gadre","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_amMOq8nGHFNugKpgOvJ0JOzchYXo4KFdCiNq_Q=s64","userId":"05393130732673909552"}},"outputId":"6f9823f7-c4b6-4620-a6b0-158cb4974751"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PqExrcvG_mVn","executionInfo":{"status":"ok","timestamp":1615787597488,"user_tz":-330,"elapsed":1565,"user":{"displayName":"Vijay Gadre","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_amMOq8nGHFNugKpgOvJ0JOzchYXo4KFdCiNq_Q=s64","userId":"05393130732673909552"}}},"source":["words = []\n","classes = []\n","documents = []\n","ignore_letters = [\",\", \"!\", \".\", \"?\"]"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ym_2LlP0_wNQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615787597488,"user_tz":-330,"elapsed":1559,"user":{"displayName":"Vijay Gadre","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_amMOq8nGHFNugKpgOvJ0JOzchYXo4KFdCiNq_Q=s64","userId":"05393130732673909552"}},"outputId":"0bde1f61-07ed-4b7d-b499-b6d710937ba9"},"source":["for intent in intents['intents']:\n","    for pattern in intent['patterns']:\n","        word_list = nltk.word_tokenize(pattern)\n","        words.extend(word_list)\n","        documents.append((word_list, intent['tag']))\n","\n","        if intent['tag'] not in classes:\n","            classes.append(intent['tag'])\n","\n","print(documents)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["[(['hello'], 'greetings'), (['hey'], 'greetings'), (['hi'], 'greetings'), (['good', 'day'], 'greetings'), (['what', \"'s\", 'up'], 'greetings'), (['how', 'is', 'it', 'going', '?'], 'greetings'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'leaving'], 'goodbye'), (['Have', 'a', 'good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['ciao'], 'goodbye'), (['see', 'yaa'], 'goodbye'), (['how', 'old'], 'age'), (['how', 'old', 'are', 'you'], 'age'), (['what', 'is', 'your', 'age'], 'age'), (['age', '?'], 'age'), (['what', 'is', 'your', 'name'], 'name'), (['what', 'should', 'I', 'call', 'you', '?'], 'name'), (['who', 'are', 'you'], 'name'), (['can', 'you', 'tell', 'me', 'your', 'name'], 'name'), (['I', \"'d\", 'like', 'to', 'buy', 'something'], 'shop'), (['what', 'would', 'you', 'recommend'], 'shop'), (['Best', 'products', 'to', 'buy'], 'shop'), (['what', 'should', 'i', 'buy'], 'shop'), (['buy'], 'shop'), (['What', 'stocks', 'do', 'i', 'own', '?'], 'stocks'), (['how', 'are', 'my', 'shares'], 'stocks'), (['What', 'companies', 'am', 'i', 'invested', 'in', '?'], 'stocks'), (['when', 'are', 'you', 'guys', 'open'], 'hours'), (['what', 'are', 'your', 'hours'], 'hours'), (['hours', 'of', 'operations'], 'hours'), (['when', 'i', 'can', 'meet', 'you'], 'hours'), (['whats', 'the', 'timing'], 'hours'), (['timing'], 'hours')]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3Tvh9d6fAb1a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615787597489,"user_tz":-330,"elapsed":1555,"user":{"displayName":"Vijay Gadre","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_amMOq8nGHFNugKpgOvJ0JOzchYXo4KFdCiNq_Q=s64","userId":"05393130732673909552"}},"outputId":"a51fde67-7b7a-4fa4-bc48-460a7c95e8e6"},"source":["words = [lemmatizer.lemmatize(word) for word in words if word not in ignore_letters]\n","words = sorted(set(words))\n","\n","classes = sorted(set(classes))\n","\n","pickle.dump(words, open('words.pk1', 'wb'))\n","pickle.dump(classes, open('classes.pk1', 'wb'))\n","\n","print(words)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["[\"'d\", \"'s\", 'Best', 'Goodbye', 'Have', 'I', 'See', 'What', 'a', 'age', 'am', 'are', 'buy', 'bye', 'call', 'can', 'ciao', 'company', 'cya', 'day', 'do', 'going', 'good', 'guy', 'hello', 'hey', 'hi', 'hour', 'how', 'i', 'in', 'invested', 'is', 'it', 'later', 'leaving', 'like', 'me', 'meet', 'my', 'name', 'of', 'old', 'open', 'operation', 'own', 'product', 'recommend', 'see', 'share', 'should', 'something', 'stock', 'tell', 'the', 'timing', 'to', 'up', 'what', 'whats', 'when', 'who', 'would', 'yaa', 'you', 'your']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zEM-P1g2Ebe-","executionInfo":{"status":"ok","timestamp":1615787597489,"user_tz":-330,"elapsed":1554,"user":{"displayName":"Vijay Gadre","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_amMOq8nGHFNugKpgOvJ0JOzchYXo4KFdCiNq_Q=s64","userId":"05393130732673909552"}}},"source":["training = []\n","output_empty = [0] * len(classes)\n","\n","for document in documents:\n","    bag = []\n","    word_patterns = document[0]\n","    word_patterns = [lemmatizer.lemmatize(word.lower()) for word in word_patterns]\n","    for word in words:\n","        bag.append(1) if word in word_patterns else bag.append(0)\n","\n","    output_row = list(output_empty)\n","    output_row[classes.index(document[1])] = 1\n","    training.append([bag, output_row])"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"L-_MX277Gka4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615787602332,"user_tz":-330,"elapsed":6393,"user":{"displayName":"Vijay Gadre","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_amMOq8nGHFNugKpgOvJ0JOzchYXo4KFdCiNq_Q=s64","userId":"05393130732673909552"}},"outputId":"00f910e1-bd4c-4c9c-a47e-429d5f6ac103"},"source":["random.shuffle(training)\n","training = np.array(training)\n","\n","train_x = list(training[:, 0])\n","train_y = list(training[:, 1])\n","\n","model = Sequential()\n","model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(len(train_y[0]), activation='softmax'))\n","\n","sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","\n","hist = model.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size=5, verbose=1)\n","model.save('chatbot_model.h5', hist)\n","print(\"Training Completed\")"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Epoch 1/200\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  \n"],"name":"stderr"},{"output_type":"stream","text":["8/8 [==============================] - 0s 2ms/step - loss: 1.9615 - accuracy: 0.1653\n","Epoch 2/200\n","8/8 [==============================] - 0s 2ms/step - loss: 2.0210 - accuracy: 0.0878\n","Epoch 3/200\n","8/8 [==============================] - 0s 2ms/step - loss: 1.8843 - accuracy: 0.1834\n","Epoch 4/200\n","8/8 [==============================] - 0s 2ms/step - loss: 1.9247 - accuracy: 0.2063\n","Epoch 5/200\n","8/8 [==============================] - 0s 2ms/step - loss: 1.8316 - accuracy: 0.2568\n","Epoch 6/200\n","8/8 [==============================] - 0s 2ms/step - loss: 1.6790 - accuracy: 0.4836\n","Epoch 7/200\n","8/8 [==============================] - 0s 2ms/step - loss: 1.6757 - accuracy: 0.3750\n","Epoch 8/200\n","8/8 [==============================] - 0s 2ms/step - loss: 1.5851 - accuracy: 0.4411\n","Epoch 9/200\n","8/8 [==============================] - 0s 2ms/step - loss: 1.5418 - accuracy: 0.5516\n","Epoch 10/200\n","8/8 [==============================] - 0s 2ms/step - loss: 1.5495 - accuracy: 0.4382\n","Epoch 11/200\n","8/8 [==============================] - 0s 2ms/step - loss: 1.5522 - accuracy: 0.5080\n","Epoch 12/200\n","8/8 [==============================] - 0s 2ms/step - loss: 1.4831 - accuracy: 0.4129\n","Epoch 13/200\n","8/8 [==============================] - 0s 2ms/step - loss: 1.3436 - accuracy: 0.5366\n","Epoch 14/200\n","8/8 [==============================] - 0s 2ms/step - loss: 1.3556 - accuracy: 0.5255\n","Epoch 15/200\n","8/8 [==============================] - 0s 2ms/step - loss: 1.2930 - accuracy: 0.4895\n","Epoch 16/200\n","8/8 [==============================] - 0s 1ms/step - loss: 1.1374 - accuracy: 0.6297\n","Epoch 17/200\n","8/8 [==============================] - 0s 2ms/step - loss: 1.1078 - accuracy: 0.5592\n","Epoch 18/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.8619 - accuracy: 0.7387\n","Epoch 19/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.9378 - accuracy: 0.6844\n","Epoch 20/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.9203 - accuracy: 0.8198\n","Epoch 21/200\n","8/8 [==============================] - 0s 3ms/step - loss: 0.7515 - accuracy: 0.7753\n","Epoch 22/200\n","8/8 [==============================] - 0s 3ms/step - loss: 0.9900 - accuracy: 0.6618\n","Epoch 23/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.8281 - accuracy: 0.6824\n","Epoch 24/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.8908\n","Epoch 25/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.6493 - accuracy: 0.7826\n","Epoch 26/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.8324\n","Epoch 27/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2704 - accuracy: 0.9601\n","Epoch 28/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.7827\n","Epoch 29/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.9105\n","Epoch 30/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7947\n","Epoch 31/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.9296\n","Epoch 32/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.8080\n","Epoch 33/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.9234\n","Epoch 34/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.8798\n","Epoch 35/200\n","8/8 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.8529\n","Epoch 36/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.9057\n","Epoch 37/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2132 - accuracy: 0.9695\n","Epoch 38/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2990 - accuracy: 0.9633\n","Epoch 39/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8807\n","Epoch 40/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1869 - accuracy: 0.9938\n","Epoch 41/200\n","8/8 [==============================] - 0s 3ms/step - loss: 0.2353 - accuracy: 0.9595\n","Epoch 42/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.9032\n","Epoch 43/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2433 - accuracy: 0.9769\n","Epoch 44/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1880 - accuracy: 0.9695\n","Epoch 45/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.9501\n","Epoch 46/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.9241\n","Epoch 47/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1631 - accuracy: 0.9390\n","Epoch 48/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.3394 - accuracy: 0.8726\n","Epoch 49/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1300 - accuracy: 0.9409\n","Epoch 50/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2823 - accuracy: 0.9187\n","Epoch 51/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1114 - accuracy: 0.9695\n","Epoch 52/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2939 - accuracy: 0.9279\n","Epoch 53/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2044 - accuracy: 0.9232\n","Epoch 54/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1770 - accuracy: 0.9695\n","Epoch 55/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1092 - accuracy: 1.0000\n","Epoch 56/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1940 - accuracy: 0.9280\n","Epoch 57/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2257 - accuracy: 0.9362\n","Epoch 58/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 1.0000\n","Epoch 59/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0523 - accuracy: 0.9769\n","Epoch 60/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1573 - accuracy: 0.9540\n","Epoch 61/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1079 - accuracy: 0.9808\n","Epoch 62/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1096 - accuracy: 0.9676\n","Epoch 63/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1517 - accuracy: 0.9362\n","Epoch 64/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1336 - accuracy: 0.9732\n","Epoch 65/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0980 - accuracy: 1.0000\n","Epoch 66/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1235 - accuracy: 0.9584\n","Epoch 67/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.2668 - accuracy: 0.9362\n","Epoch 68/200\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1360 - accuracy: 0.9465\n","Epoch 69/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0615 - accuracy: 1.0000\n","Epoch 70/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1685 - accuracy: 0.9602\n","Epoch 71/200\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 1.0000\n","Epoch 72/200\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.9907\n","Epoch 73/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0977 - accuracy: 0.9769\n","Epoch 74/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1155 - accuracy: 0.9769\n","Epoch 75/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0702 - accuracy: 0.9695\n","Epoch 76/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0849 - accuracy: 0.9676\n","Epoch 77/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0880 - accuracy: 1.0000\n","Epoch 78/200\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0738 - accuracy: 0.9825\n","Epoch 79/200\n","8/8 [==============================] - 0s 3ms/step - loss: 0.1046 - accuracy: 0.9869\n","Epoch 80/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1033 - accuracy: 0.9869\n","Epoch 81/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1511 - accuracy: 0.9584\n","Epoch 82/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 1.0000\n","Epoch 83/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 1.0000\n","Epoch 84/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1200 - accuracy: 0.9695\n","Epoch 85/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0886 - accuracy: 0.9907\n","Epoch 86/200\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 1.0000\n","Epoch 87/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 1.0000\n","Epoch 88/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 1.0000\n","Epoch 89/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 1.0000\n","Epoch 90/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0415 - accuracy: 1.0000\n","Epoch 91/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0783 - accuracy: 1.0000\n","Epoch 92/200\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 1.0000\n","Epoch 93/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.9695\n","Epoch 94/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 1.0000\n","Epoch 95/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0917 - accuracy: 1.0000\n","Epoch 96/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 1.0000\n","Epoch 97/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 1.0000\n","Epoch 98/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 1.0000\n","Epoch 99/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 1.0000\n","Epoch 100/200\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.9869\n","Epoch 101/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0456 - accuracy: 1.0000\n","Epoch 102/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 1.0000\n","Epoch 103/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.9825\n","Epoch 104/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0411 - accuracy: 0.9869\n","Epoch 105/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1011 - accuracy: 1.0000\n","Epoch 106/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0785 - accuracy: 0.9769\n","Epoch 107/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 1.0000\n","Epoch 108/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 0.9907\n","Epoch 109/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 1.0000\n","Epoch 110/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0510 - accuracy: 0.9769\n","Epoch 111/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 1.0000\n","Epoch 112/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 1.0000\n","Epoch 113/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 1.0000\n","Epoch 114/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0235 - accuracy: 1.0000\n","Epoch 115/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 1.0000\n","Epoch 116/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 1.0000\n","Epoch 117/200\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 1.0000\n","Epoch 118/200\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0251 - accuracy: 1.0000\n","Epoch 119/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 1.0000\n","Epoch 120/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0998 - accuracy: 0.9695\n","Epoch 121/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 0.9869\n","Epoch 122/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9676\n","Epoch 123/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 1.0000\n","Epoch 124/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 1.0000\n","Epoch 125/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 0.9825\n","Epoch 126/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.9769\n","Epoch 127/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 1.0000\n","Epoch 128/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1124 - accuracy: 0.9869\n","Epoch 129/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0520 - accuracy: 0.9825\n","Epoch 130/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0442 - accuracy: 1.0000\n","Epoch 131/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0130 - accuracy: 1.0000\n","Epoch 132/200\n","8/8 [==============================] - 0s 6ms/step - loss: 0.0390 - accuracy: 0.9825\n","Epoch 133/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 1.0000\n","Epoch 134/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 1.0000\n","Epoch 135/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0747 - accuracy: 0.9769\n","Epoch 136/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000\n","Epoch 137/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0310 - accuracy: 1.0000\n","Epoch 138/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1164 - accuracy: 1.0000\n","Epoch 139/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 1.0000\n","Epoch 140/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 1.0000\n","Epoch 141/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 1.0000\n","Epoch 142/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0871 - accuracy: 0.9869\n","Epoch 143/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0125 - accuracy: 1.0000\n","Epoch 144/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy: 1.0000\n","Epoch 145/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0727 - accuracy: 0.9584\n","Epoch 146/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0741 - accuracy: 1.0000\n","Epoch 147/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 1.0000\n","Epoch 148/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 1.0000\n","Epoch 149/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1105 - accuracy: 0.9584\n","Epoch 150/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0833 - accuracy: 0.9695\n","Epoch 151/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1022 - accuracy: 0.9354\n","Epoch 152/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 1.0000\n","Epoch 153/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 1.0000\n","Epoch 154/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 1.0000\n","Epoch 155/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 1.0000\n","Epoch 156/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0830 - accuracy: 0.9584\n","Epoch 157/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 1.0000\n","Epoch 158/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1064 - accuracy: 0.9769\n","Epoch 159/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0944 - accuracy: 1.0000\n","Epoch 160/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 1.0000\n","Epoch 161/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 1.0000\n","Epoch 162/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 1.0000\n","Epoch 163/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.9813\n","Epoch 164/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 0.9938\n","Epoch 165/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1192 - accuracy: 0.9354\n","Epoch 166/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n","Epoch 167/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0512 - accuracy: 1.0000\n","Epoch 168/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0162 - accuracy: 1.0000\n","Epoch 169/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 1.0000\n","Epoch 170/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 1.0000\n","Epoch 171/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.1559 - accuracy: 0.9362\n","Epoch 172/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 1.0000\n","Epoch 173/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000\n","Epoch 174/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 1.0000\n","Epoch 175/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.9907\n","Epoch 176/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 1.0000\n","Epoch 177/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 1.0000\n","Epoch 178/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 1.0000\n","Epoch 179/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 1.0000\n","Epoch 180/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 1.0000\n","Epoch 181/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0494 - accuracy: 1.0000\n","Epoch 182/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 1.0000\n","Epoch 183/200\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 1.0000\n","Epoch 184/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 1.0000\n","Epoch 185/200\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0843 - accuracy: 0.9362\n","Epoch 186/200\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 1.0000\n","Epoch 187/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0130 - accuracy: 1.0000\n","Epoch 188/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0596 - accuracy: 1.0000\n","Epoch 189/200\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000\n","Epoch 190/200\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 1.0000\n","Epoch 191/200\n","8/8 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 1.0000\n","Epoch 192/200\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 1.0000\n","Epoch 193/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000\n","Epoch 194/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000\n","Epoch 195/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0415 - accuracy: 0.9584\n","Epoch 196/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 1.0000\n","Epoch 197/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000\n","Epoch 198/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 1.0000\n","Epoch 199/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 1.0000\n","Epoch 200/200\n","8/8 [==============================] - 0s 2ms/step - loss: 0.0906 - accuracy: 0.9869\n","Training Completed\n"],"name":"stdout"}]}]}